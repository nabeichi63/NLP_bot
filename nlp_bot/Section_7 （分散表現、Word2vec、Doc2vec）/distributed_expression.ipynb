{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分散表現の確認\n",
    "word2vecによる分散表現について学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コーパスの前処理\n",
    "前のセクションと同様に、コーパスに前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "with open(\"wagahaiwa_nekodearu.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
    "    wagahai_original = f.read()\n",
    "\n",
    "wagahai = re.sub(\"《[^》]+》\", \"\", wagahai_original) # ルビの削除\n",
    "wagahai = re.sub(\"［[^］]+］\", \"\", wagahai) # 読みの注意の削除\n",
    "wagahai = re.sub(\"[｜ 　「」\\n]\", \"\", wagahai) # | と全角半角スペース、「」と改行の削除\n",
    "\n",
    "seperator = \"。\"  # 。をセパレータに指定\n",
    "wagahai_list = wagahai.split(seperator)  # セパレーターを使って文章をリストに分割する\n",
    "wagahai_list.pop() # 最後の要素は空の文字列になるので、削除\n",
    "wagahai_list = [x+seperator for x in wagahai_list]  # 文章の最後に。を追加\n",
    "        \n",
    "t = Tokenizer()\n",
    "\n",
    "wagahai_words = []\n",
    "for sentence in wagahai_list:\n",
    "    wagahai_words.append(t.tokenize(sentence, wakati=True))   # 文章ごとに単語に分割し、リストに格納\n",
    "    \n",
    "with open('wagahai_words.pickle', mode='wb') as f:  # pickleに保存\n",
    "    pickle.dump(wagahai_words, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存できていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['吾輩', 'は', '猫', 'で', 'ある', '。'], ['名前', 'は', 'まだ', '無い', '。'], ['どこ', 'で', '生れ', 'た', 'か', 'とんと', '見当', 'が', 'つか', 'ぬ', '。'], ['何', 'でも', '薄暗い', 'じめじめ', 'し', 'た', '所', 'で', 'ニャーニャー', '泣い', 'て', 'いた事', 'だけ', 'は', '記憶', 'し', 'て', 'いる', '。'], ['吾輩', 'は', 'ここ', 'で', '始め', 'て', '人間', 'という', 'もの', 'を', '見', 'た', '。'], ['しかも', 'あと', 'で', '聞く', 'と', 'それ', 'は', '書生', 'という', '人間', '中', 'で', '一番', '獰悪', 'な', '種族', 'で', 'あっ', 'た', 'そう', 'だ', '。'], ['この', '書生', 'という', 'の', 'は', '時々', '我々', 'を', '捕え', 'て', '煮', 'て', '食う', 'という', '話', 'で', 'ある', '。'], ['しかし', 'その', '当時', 'は', '何', 'という', '考', 'も', 'なかっ', 'た', 'から', '別段', '恐し', 'いとも', '思わ', 'なかっ', 'た', '。'], ['ただ', '彼', 'の', '掌', 'に', '載せ', 'られ', 'て', 'スー', 'と', '持ち上げ', 'られ', 'た', '時', '何だか', 'フワフワ', 'し', 'た', '感じ', 'が', 'あっ', 'た', 'ばかり', 'で', 'ある', '。'], ['掌', 'の', '上', 'で', '少し', '落ちつい', 'て', '書生', 'の', '顔', 'を', '見', 'た', 'の', 'が', 'いわゆる', '人間', 'という', 'もの', 'の', '見', '始', 'で', 'あろ', 'う', '。']]\n"
     ]
    }
   ],
   "source": [
    "with open('wagahai_words.pickle', mode='rb') as f:\n",
    "    wagahai_words = pickle.load(f)\n",
    "\n",
    "print(wagahai_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vecを用いた学習\n",
    "今回はword2vecのためにライブラリgensimを使います。  \n",
    "gensimは、様々なトピックモデルを実装したPythonライブラリです。  \n",
    "トピックモデルとは、潜在的なトピックから文章が確率的に生成されると仮定したモデルです。\n",
    "\n",
    "gensimについて、詳細は以下のリンクを参考にどうぞ。  \n",
    "https://radimrehurek.com/gensim/\n",
    "\n",
    "以下では、word2vecを用いてコーパスの学習を行い、学習済みのモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichi/anaconda3/envs/nlp_bot/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# size : 中間層のニューロン数\n",
    "# min_count : この値以下の出現回数の単語を無視\n",
    "# window : 対象単語を中心とした前後の単語数\n",
    "# iter : epochs数\n",
    "# sg : skip-gramを使うかどうか 0:CBOW 1:skip-gram\n",
    "model = word2vec.Word2Vec(wagahai_words,\n",
    "                          size=100,\n",
    "                          min_count=5,\n",
    "                          window=5,\n",
    "                          iter=20,\n",
    "                          sg = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分散表現を見ていきましょう。  \n",
    "重みを表す行列（分散表現）の形状と、行列そのものを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3309, 100)\n",
      "[[-0.09066485 -0.34604695  0.7273088  ...  0.04224892 -0.82164377\n",
      "  -0.46398592]\n",
      " [ 0.8837304  -1.0933285  -0.85261196 ...  1.1640803   0.07897197\n",
      "  -0.04611873]\n",
      " [ 0.65802133  1.075583   -1.6616772  ...  0.41787034  0.50785375\n",
      "   0.1475225 ]\n",
      " ...\n",
      " [-0.26548645 -0.17901473 -0.05735658 ... -0.11305621 -0.23449193\n",
      "  -0.1642286 ]\n",
      " [-0.28336552  0.13049659  0.09530248 ... -0.04149596 -0.10335829\n",
      "   0.23502997]\n",
      " [-0.22602312 -0.12524003  0.02362706 ...  0.07721136 -0.20836633\n",
      "   0.09439667]]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.vectors.shape)  # 分散表現の形状\n",
    "print(model.wv.vectors)  # 分散表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "語彙の数、および語彙の最初の10語を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309\n",
      "['の', '。', 'て', '、', 'は', 'に', 'を', 'と', 'が', 'た']\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.index2word))  # 語彙の数\n",
    "print(model.wv.index2word[:10])  # 最初の10単語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "語彙における、最初の単語の単語ベクトルを2通りの方法で表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09066485 -0.34604695  0.7273088  -0.34618434 -1.3970566   0.5536664\n",
      " -0.20120287  0.28109583  0.49728593 -0.25257882 -0.23142174 -0.47463962\n",
      " -0.01719849  0.1876312  -0.6249548   0.04314373 -0.35894844 -0.56862247\n",
      " -0.54742956 -0.00422385  0.87078375  0.7371037   0.8350606  -0.7722595\n",
      " -0.69106466  0.16500892  0.4339562   0.44498098  0.45013857  0.4200448\n",
      "  0.13794768  0.14409739  0.61041355 -0.00647598  0.13639343  0.553947\n",
      " -0.8512681   1.2668073   0.29163602  1.0049824   0.22195426 -0.7821805\n",
      " -0.55875975  0.7221586   0.36714    -0.11408418  0.3495171   0.23651236\n",
      "  0.6695625   0.227487    0.01526225  0.6441438   0.04174218 -0.12470559\n",
      "  0.3624151  -0.03855456  0.80626565  0.7223268   1.1626136  -0.4580562\n",
      " -0.06326619  0.08574797  0.03875536 -0.46689123 -0.5862244   0.67781717\n",
      "  0.8008343  -0.748451   -0.30978292  0.6297956  -0.334449    0.03905291\n",
      "  0.9057295   0.71364224  0.34691912 -0.16187002 -0.20038664 -0.29113027\n",
      " -0.21348253 -0.26536742 -0.44618797 -0.15645869  0.31462246 -0.31394434\n",
      " -0.27458975 -0.52309203  0.60311294 -0.05970157 -0.2080851   0.6251072\n",
      "  0.6129362  -0.6197362  -0.42282495  0.21319708 -0.54993063 -0.12253796\n",
      "  0.5438931   0.04224892 -0.82164377 -0.46398592]\n",
      "[-0.09066485 -0.34604695  0.7273088  -0.34618434 -1.3970566   0.5536664\n",
      " -0.20120287  0.28109583  0.49728593 -0.25257882 -0.23142174 -0.47463962\n",
      " -0.01719849  0.1876312  -0.6249548   0.04314373 -0.35894844 -0.56862247\n",
      " -0.54742956 -0.00422385  0.87078375  0.7371037   0.8350606  -0.7722595\n",
      " -0.69106466  0.16500892  0.4339562   0.44498098  0.45013857  0.4200448\n",
      "  0.13794768  0.14409739  0.61041355 -0.00647598  0.13639343  0.553947\n",
      " -0.8512681   1.2668073   0.29163602  1.0049824   0.22195426 -0.7821805\n",
      " -0.55875975  0.7221586   0.36714    -0.11408418  0.3495171   0.23651236\n",
      "  0.6695625   0.227487    0.01526225  0.6441438   0.04174218 -0.12470559\n",
      "  0.3624151  -0.03855456  0.80626565  0.7223268   1.1626136  -0.4580562\n",
      " -0.06326619  0.08574797  0.03875536 -0.46689123 -0.5862244   0.67781717\n",
      "  0.8008343  -0.748451   -0.30978292  0.6297956  -0.334449    0.03905291\n",
      "  0.9057295   0.71364224  0.34691912 -0.16187002 -0.20038664 -0.29113027\n",
      " -0.21348253 -0.26536742 -0.44618797 -0.15645869  0.31462246 -0.31394434\n",
      " -0.27458975 -0.52309203  0.60311294 -0.05970157 -0.2080851   0.6251072\n",
      "  0.6129362  -0.6197362  -0.42282495  0.21319708 -0.54993063 -0.12253796\n",
      "  0.5438931   0.04224892 -0.82164377 -0.46398592]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.vectors[0])  # 最初のベクトル\n",
    "print(model.wv.__getitem__(\"の\"))  # 最初の単語「の」のベクトル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "両者ともに同じベクトルですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題:\n",
    "単語「猫」を単語ベクトルで表してみましょう。  \n",
    "また、skip-gramも試して結果を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3809053   0.16722488 -0.36461446  0.02259765 -1.3288645  -0.388068\n",
      " -0.7087186  -0.18947956 -0.22555123  0.55967957  1.7615225  -0.904422\n",
      " -0.1189886   0.14004831 -0.9426482   0.22964063  0.21640897 -0.7614045\n",
      "  0.20025733 -0.3442679  -0.22510293  0.96821517 -0.5788678  -0.89460653\n",
      "  0.30407584  0.08574077  0.93062913  0.2171532   0.52828634 -0.29456225\n",
      " -0.03026406  0.41187462 -1.0500183   0.8276303   0.6971914   0.96790534\n",
      " -0.8718102  -0.5076668   0.42881322 -0.72611713  1.1867819  -0.9338218\n",
      "  0.4505887  -0.2815317  -0.47966138  0.12031621 -0.04077093  0.6287539\n",
      "  0.3652754   0.24723427 -1.5607516   0.4050069  -0.31857204  0.5459491\n",
      "  0.1406853  -0.07546253 -0.67745245 -0.05685529 -1.1660954  -0.055898\n",
      " -0.02921543  0.29763645  0.22826952 -0.7356843  -0.29710373  0.13666658\n",
      "  0.53164464 -0.26691344  0.82227105  0.01404501  0.05552771  0.59246796\n",
      " -0.36092564 -0.11931354 -0.38206252  0.25175264  0.12638308  0.17031397\n",
      " -0.33364686 -0.27559164 -0.44288    -1.265253    1.2487862   0.2646064\n",
      " -0.9986163   1.1481534   0.41681886 -0.07473903 -0.04342571 -0.27315316\n",
      "  0.18716998 -1.2752538  -0.7334276   0.44802135  0.19439451  0.25236014\n",
      " -0.10971928  0.09865316 -0.7198661  -1.7189469 ]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.__getitem__('猫'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size : 中間層のニューロン数\n",
    "# min_count : この値以下の出現回数の単語を無視\n",
    "# window : 対象単語を中心とした前後の単語数\n",
    "# iter : epochs数\n",
    "# sg : skip-gramを使うかどうか 0:CBOW 1:skip-gram\n",
    "model_sg = word2vec.Word2Vec(wagahai_words,\n",
    "                          size=100,\n",
    "                          min_count=5,\n",
    "                          window=5,\n",
    "                          iter=20,\n",
    "                          sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309\n",
      "['の', '。', 'て', '、', 'は', 'に', 'を', 'と', 'が', 'た']\n"
     ]
    }
   ],
   "source": [
    "print(len(model_sg.wv.index2word))  # 語彙の数\n",
    "print(model_sg.wv.index2word[:10])  # 最初の10単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02423393 -0.09957796  0.0826341   0.17812987 -0.10110112  0.07051703\n",
      " -0.1260978  -0.07167327  0.21021448  0.15734701  0.01998097 -0.05634838\n",
      "  0.20348744  0.36543038 -0.473994    0.26897126 -0.19591446 -0.08518056\n",
      " -0.15099578 -0.03783957 -0.10159198  0.08857406  0.13592623 -0.08368187\n",
      "  0.12383232 -0.15468751  0.08899155 -0.14827965  0.35481945  0.13122861\n",
      "  0.04559382 -0.11652306  0.06142838  0.41111454  0.07662544  0.4511924\n",
      " -0.16815914  0.11067397  0.07261885 -0.16989355  0.33924565 -0.17385936\n",
      "  0.06868327  0.25662345  0.2503879   0.0273607   0.16625619  0.1512245\n",
      " -0.07015059 -0.09325917  0.00553523  0.19578733  0.04133367  0.00440472\n",
      "  0.01319202  0.19031574  0.02158524  0.14308569  0.43092188  0.02413888\n",
      "  0.18238313 -0.0029405   0.02542878  0.10960009  0.25837904  0.40308547\n",
      "  0.42264497 -0.00358669 -0.01785381  0.16761342 -0.08639672  0.18014295\n",
      "  0.3880545   0.10811688  0.11711922 -0.04598468  0.10423324  0.1360945\n",
      " -0.04205678 -0.30246454 -0.03573402  0.18685494 -0.16018103 -0.21754809\n",
      "  0.04621816 -0.17026892  0.22805817  0.22544585 -0.19121026  0.10933369\n",
      " -0.24531047  0.06487731  0.14861114 -0.01930745 -0.3385448   0.0801267\n",
      "  0.17194822  0.02997379 -0.10428634  0.2173032 ]\n",
      "[-0.02423393 -0.09957796  0.0826341   0.17812987 -0.10110112  0.07051703\n",
      " -0.1260978  -0.07167327  0.21021448  0.15734701  0.01998097 -0.05634838\n",
      "  0.20348744  0.36543038 -0.473994    0.26897126 -0.19591446 -0.08518056\n",
      " -0.15099578 -0.03783957 -0.10159198  0.08857406  0.13592623 -0.08368187\n",
      "  0.12383232 -0.15468751  0.08899155 -0.14827965  0.35481945  0.13122861\n",
      "  0.04559382 -0.11652306  0.06142838  0.41111454  0.07662544  0.4511924\n",
      " -0.16815914  0.11067397  0.07261885 -0.16989355  0.33924565 -0.17385936\n",
      "  0.06868327  0.25662345  0.2503879   0.0273607   0.16625619  0.1512245\n",
      " -0.07015059 -0.09325917  0.00553523  0.19578733  0.04133367  0.00440472\n",
      "  0.01319202  0.19031574  0.02158524  0.14308569  0.43092188  0.02413888\n",
      "  0.18238313 -0.0029405   0.02542878  0.10960009  0.25837904  0.40308547\n",
      "  0.42264497 -0.00358669 -0.01785381  0.16761342 -0.08639672  0.18014295\n",
      "  0.3880545   0.10811688  0.11711922 -0.04598468  0.10423324  0.1360945\n",
      " -0.04205678 -0.30246454 -0.03573402  0.18685494 -0.16018103 -0.21754809\n",
      "  0.04621816 -0.17026892  0.22805817  0.22544585 -0.19121026  0.10933369\n",
      " -0.24531047  0.06487731  0.14861114 -0.01930745 -0.3385448   0.0801267\n",
      "  0.17194822  0.02997379 -0.10428634  0.2173032 ]\n"
     ]
    }
   ],
   "source": [
    "print(model_sg.wv.vectors[0])  # 最初のベクトル\n",
    "print(model_sg.wv.__getitem__(\"の\"))  # 最初の単語「の」のベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3809053   0.16722488 -0.36461446  0.02259765 -1.3288645  -0.388068\n",
      " -0.7087186  -0.18947956 -0.22555123  0.55967957  1.7615225  -0.904422\n",
      " -0.1189886   0.14004831 -0.9426482   0.22964063  0.21640897 -0.7614045\n",
      "  0.20025733 -0.3442679  -0.22510293  0.96821517 -0.5788678  -0.89460653\n",
      "  0.30407584  0.08574077  0.93062913  0.2171532   0.52828634 -0.29456225\n",
      " -0.03026406  0.41187462 -1.0500183   0.8276303   0.6971914   0.96790534\n",
      " -0.8718102  -0.5076668   0.42881322 -0.72611713  1.1867819  -0.9338218\n",
      "  0.4505887  -0.2815317  -0.47966138  0.12031621 -0.04077093  0.6287539\n",
      "  0.3652754   0.24723427 -1.5607516   0.4050069  -0.31857204  0.5459491\n",
      "  0.1406853  -0.07546253 -0.67745245 -0.05685529 -1.1660954  -0.055898\n",
      " -0.02921543  0.29763645  0.22826952 -0.7356843  -0.29710373  0.13666658\n",
      "  0.53164464 -0.26691344  0.82227105  0.01404501  0.05552771  0.59246796\n",
      " -0.36092564 -0.11931354 -0.38206252  0.25175264  0.12638308  0.17031397\n",
      " -0.33364686 -0.27559164 -0.44288    -1.265253    1.2487862   0.2646064\n",
      " -0.9986163   1.1481534   0.41681886 -0.07473903 -0.04342571 -0.27315316\n",
      "  0.18716998 -1.2752538  -0.7334276   0.44802135  0.19439451  0.25236014\n",
      " -0.10971928  0.09865316 -0.7198661  -1.7189469 ]\n",
      "[-0.1450005   0.07216725 -0.30720502  0.42350444 -0.73717266 -0.45019472\n",
      " -0.06773572  0.267589    0.6674022   0.23252396  0.6700299  -0.36050907\n",
      " -0.06263907  0.23464239 -0.29601756  0.17718534 -0.13472492 -0.2467013\n",
      "  0.12734467  0.20633058  0.44765857 -0.5451498  -0.20214382 -0.4275449\n",
      "  0.3998873   0.17828375  0.489453    0.3315661  -0.476163   -0.30409658\n",
      " -0.3392935   0.0992024   0.25654727  0.6376069   0.06718758  0.38577026\n",
      " -0.1638425  -0.35416755  0.23042962 -0.36159623  0.6859726  -0.33066306\n",
      " -0.00671975  0.06519414 -0.044241   -0.01500979  0.45906198  0.33815867\n",
      "  0.08343484  0.11127642 -0.6910332   0.3011943   0.04915401  0.33106294\n",
      "  0.3631649   0.2948524  -0.1863574  -0.2772519  -0.33015084 -0.04100099\n",
      "  0.3394376   0.0865102   0.22813436  0.14927742 -0.23225705  0.04740878\n",
      "  0.144248   -0.6736043   0.3006529   0.18558529  0.18114614  0.4938206\n",
      "  0.5235779   0.606944    0.11289155  0.11978028  0.41418308  0.34044638\n",
      "  0.550726   -0.53405654  0.2116672  -0.36872515  0.20461361  0.01857046\n",
      " -0.40883994 -0.40996     0.4651161  -0.7366461   0.24799289 -0.22302094\n",
      "  0.3942305  -0.24560857  0.30457467  0.19601014 -0.11302759 -0.1149293\n",
      "  0.40413737  0.07428714 -0.4028178   0.48535866]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.__getitem__('猫'))\n",
    "print(model_sg.wv.__getitem__('猫'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 何を比較しろと言っているのかな？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
